{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-09T16:19:31.058214Z",
     "iopub.status.busy": "2022-04-09T16:19:31.05797Z",
     "iopub.status.idle": "2022-04-09T16:19:31.061825Z",
     "shell.execute_reply": "2022-04-09T16:19:31.061256Z",
     "shell.execute_reply.started": "2022-04-09T16:19:31.05818Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = '/kaggle/input/apple-disease-dataset/datasets'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = (224, 224) # efficienetB0, ResNet50V2, DenseNet121, MobileNetV2\n",
    "# image_size = (240, 240) # efficienetB1\n",
    "# image_size = (260, 260) # efficienetB2\n",
    "image_size = (300, 300) # efficienetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shapes = (224, 224, 3) # efficienetB0, ResNet50V2, DenseNet121, MobileNetV2\n",
    "# input_shapes = (240, 240, 3) # efficienetB1\n",
    "# input_shapes = (260, 260, 3) # efficienetB2\n",
    "input_shapes = (300, 300, 3) # efficienetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "LEARNING_RATE=0.0001\n",
    "num_classes=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdata=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False, samplewise_center=False,\n",
    "    featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "    rotation_range=0, width_shift_range=0.0, height_shift_range=0.0,\n",
    "    brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0,\n",
    "    horizontal_flip=False, vertical_flip=False,\n",
    "    validation_split=0.2, rescale=1./255\n",
    ")\n",
    "\n",
    "train_ds = trdata.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=image_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_ds = trdata.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=image_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "testdata=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False, samplewise_center=False,\n",
    "    featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "    rotation_range=0, width_shift_range=0.0, height_shift_range=0.0,\n",
    "    brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0,\n",
    "    horizontal_flip=False, vertical_flip=False, rescale=1./255\n",
    ")\n",
    "\n",
    "test_ds = testdata.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=image_size,\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_ds)\n",
    "\n",
    "_, axs = plt.subplots(4, 8, figsize=(20, 10))\n",
    "axs = axs.flatten()\n",
    "for i, ax in zip(range(0, 32), axs):\n",
    "    image = x_batch[i]\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(image)\n",
    "\n",
    "plt.savefig(\"preprocessed.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "# base_model = EfficientNetB0(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n",
    "# base_model = EfficientNetB1(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n",
    "# base_model = EfficientNetB2(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n",
    "base_model = EfficientNetB3(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n",
    "# base_model = ResNet50V2(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n",
    "# base_model = DenseNet121(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n",
    "# base_model = MobileNetV2(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n",
    "\n",
    "x = base_model.output   \n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Start of Neural Network Part\n",
    "x = Dense(512,activation='sigmoid')(x)    # 128/256/512/1024\n",
    "x = BatchNormalization()(x)\n",
    "#x = Activation(swish_act)(x)\n",
    "x = Dropout(0.5)(x)  # 0.1/0.2/0.3/0.5/0.6/0.7\n",
    "\n",
    "x = Dense(128,activation='sigmoid')(x)   # 128/256/512/1024\n",
    "x = BatchNormalization()(x)\n",
    "#x = Activation(swish_act)(x)\n",
    "x = Dropout(0.7)(x)  # 0.1/0.2/0.3/0.5/0.6/0.7\n",
    "\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model= Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=LEARNING_RATE),metrics=['acc'])\n",
    "model.summary()\n",
    "model.save('model_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint('effB3.h5', monitor='val_acc',save_best_only=True,)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "history=model.fit(train_ds, epochs=epochs, callbacks=[checkpoint,early], validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from itertools import product\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model.load_weights('effB3.h5')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes, rotation=0)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range (cm.shape[0]):\n",
    "        for j in range (cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnf_B3.jpg')\n",
    "\n",
    "class_labels = test_ds.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "\n",
    "Y_pred = model.predict_generator(test_ds)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "target_names = list(class_labels.values())\n",
    "\n",
    "predicted_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(test_ds.classes, y_pred)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes,\n",
    "                      title='')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(test_ds.classes, y_pred, target_names=target_names,digits=4))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2068739,
     "sourceId": 3433042,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30177,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
